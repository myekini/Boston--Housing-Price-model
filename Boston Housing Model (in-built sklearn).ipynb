{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "48afa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "587f2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"housing.csv\"\n",
    "#load data and read into dataframe\n",
    "califonia_data = pd.read_csv(PATH)\n",
    "\n",
    "#drop down NaN and display dataframe\n",
    "#califonia_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "a931a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "califonia_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "6d42ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting prediction target(house value)\n",
    "y = califonia_data.median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "56125799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features to be considered for prediction\n",
    "features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'population', 'households', 'median_income', 'total_bedrooms', 'ocean_proximity',]\n",
    "\n",
    "#setting Features\n",
    "X = califonia_data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "ee4622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to get training and validation data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X,y, random_state=0)\n",
    "\n",
    "#train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "74b79aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for prediting and evaluating our dataset\n",
    "def score_all(train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y,preds)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "d1d9afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical variables\n",
      "['ocean_proximity']\n"
     ]
    }
   ],
   "source": [
    "# columns with categorical variables \n",
    "s = (train_X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"categorical variables\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "bad192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second approach is to ordinal encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#make copy to avoid changing original data\n",
    "label_X_train = train_X.copy()\n",
    "label_X_val = val_X.copy()\n",
    "\n",
    "#apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(train_X[object_cols])\n",
    "label_X_val[object_cols] = ordinal_encoder.fit_transform(val_X[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "c0eba0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from 2nd approach \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32406.613267441862"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second approach to handling missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer() # Your code here\n",
    "imputed_train_X = pd.DataFrame(my_imputer.fit_transform(label_X_train))\n",
    "imputed_val_X = pd.DataFrame(my_imputer.transform(label_X_val))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_train_X.columns = label_X_train.columns\n",
    "imputed_val_X.columns = label_X_val.columns\n",
    "\n",
    "print(\"MAE from 2nd approach \")\n",
    "score_all(imputed_train_X, imputed_val_X, train_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "862649de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42881.26162790698"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the model with a random state equals 1\n",
    "califonia_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "#fit data and #make predictions\n",
    "califonia_model.fit(imputed_train_X, train_y)\n",
    "preds = califonia_model.predict(imputed_val_X)\n",
    "\n",
    "def scoreall(val_y,preds):\n",
    "    mae = mean_absolute_error(val_y,preds)\n",
    "    return mae\n",
    "\n",
    "scoreall(val_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "74e682ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32406.613267441862"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a better predictions with RandomForestRegressor and make predictions\n",
    "\n",
    "califonia_model_2 = RandomForestRegressor(random_state=1)\n",
    "califonia_model_2.fit(imputed_train_X, train_y)\n",
    "preds_2 = califonia_model_2.predict(imputed_val_X)\n",
    "\n",
    "\n",
    "#measuring the quality of the data\n",
    "\n",
    "def scoreall(val_y,preds_2 ):\n",
    "    mae = mean_absolute_error(val_y,preds_2)\n",
    "    return mae\n",
    "\n",
    "scoreall(val_y, preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "348b10c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 31822.118939922486\n"
     ]
    }
   ],
   "source": [
    "# using pipelines to simplify preprocessing and modelling\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#define numerical and categorical columns\n",
    "numerical_cols = [col for col in train_X.columns\n",
    "                if train_X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "categorical_cols = [col for col in train_X.columns\n",
    "                 if train_X[col].dtype == 'object' and\n",
    "                 if train_X[col].nunique() < 10]\n",
    "\n",
    "# preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "#preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps= [\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "#binding the numerical and categorical preprocessing \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, numerical_cols),\n",
    "                  ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "#define the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "\n",
    "# create pipeline for preprocessing and modelling\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "#fit data and make predictions\n",
    "my_pipeline.fit(train_X, train_y)\n",
    "\n",
    "#preprocess of validation of validation data and get prediction\n",
    "\n",
    "preds = my_pipeline.predict(val_X)\n",
    "\n",
    "#evaluate the model\n",
    "score = mean_absolute_error(val_y, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d48b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
