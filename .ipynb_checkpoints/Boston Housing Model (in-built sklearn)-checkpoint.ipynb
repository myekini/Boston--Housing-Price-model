{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "48afa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "587f2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"housing.csv\"\n",
    "#load data and read into dataframe\n",
    "califonia_data = pd.read_csv(PATH)\n",
    "\n",
    "#drop down NaN and display dataframe\n",
    "#califonia_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "a931a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "califonia_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "6d42ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting prediction target(house value)\n",
    "y = califonia_data.median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "56125799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>total_bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>537.870553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>421.385070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>6445.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "         population    households  median_income  total_bedrooms  \n",
       "count  20640.000000  20640.000000   20640.000000    20433.000000  \n",
       "mean    1425.476744    499.539680       3.870671      537.870553  \n",
       "std     1132.462122    382.329753       1.899822      421.385070  \n",
       "min        3.000000      1.000000       0.499900        1.000000  \n",
       "25%      787.000000    280.000000       2.563400      296.000000  \n",
       "50%     1166.000000    409.000000       3.534800      435.000000  \n",
       "75%     1725.000000    605.000000       4.743250      647.000000  \n",
       "max    35682.000000   6082.000000      15.000100     6445.000000  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features to be considered for prediction\n",
    "features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'population', 'households', 'median_income', 'total_bedrooms', 'ocean_proximity',]\n",
    "\n",
    "#setting Features\n",
    "X = califonia_data[features]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "ee4622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to get training and validation data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X,y, random_state=0)\n",
    "\n",
    "#train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "74b79aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for prediting and evaluating our dataset\n",
    "def score_all(train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y,preds)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "d1d9afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             False\n",
      "latitude              False\n",
      "housing_median_age    False\n",
      "total_rooms           False\n",
      "population            False\n",
      "households            False\n",
      "median_income         False\n",
      "total_bedrooms        False\n",
      "ocean_proximity        True\n",
      "dtype: bool\n",
      "categorical variables\n",
      "['ocean_proximity']\n"
     ]
    }
   ],
   "source": [
    "# columns with categorical variables \n",
    "s = (train_X.dtypes == 'object')\n",
    "print(s)\n",
    "object_cols = list(s[s].index)\n",
    "print(\"categorical variables\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "71f60daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first approach is to drop thes columns \n",
    "train_X_dropped = train_X.select_dtypes(exclude=['object'])\n",
    "val_X_dropped = val_X.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "bad192f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second approach is to ordinal encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#make copy to avoid changing original data\n",
    "label_X_train = train_X.copy()\n",
    "label_X_val = val_X.copy()\n",
    "\n",
    "#apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(train_X[object_cols])\n",
    "label_X_val[object_cols] = ordinal_encoder.fit_transform(val_X[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "e84a2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd approach for handling categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown= 'ignore', sparse= False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[object_cols]))\n",
    "OH_cols_val = pd.DataFrame(OH_encoder.fit_transform(val_X[object_cols]))\n",
    "\n",
    "#one hot encoding removed index. put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_val.index = val_X.index\n",
    "\n",
    "#removed categorical columns (will replace with one-hot encoding)\n",
    "num_train_X = train_X.drop(object_cols, axis=1)\n",
    "num_val_X = val_X.drop(object_cols, axis=1)\n",
    "\n",
    "# add one - hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_train_X, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_val_X, OH_cols_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "12948181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from dropping columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32195.37646511628"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First (1st) approach to handlling missing data, get columns with missing data\n",
    "col_with_missing = [col for col in label_X_train.columns\n",
    "                   if label_X_train[col].isnull().any()]\n",
    "\n",
    "train_X_reduced = label_X_train.drop(col_with_missing, axis=1)\n",
    "val_X_reduced = label_X_val.drop(col_with_missing, axis=1)\n",
    "\n",
    "print (\"MAE from dropping columns\")\n",
    "score_all(train_X_reduced, val_X_reduced, train_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "c0eba0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from 2nd approach \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32406.613267441862"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second approach to handling missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer() # Your code here\n",
    "imputed_train_X = pd.DataFrame(my_imputer.fit_transform(label_X_train))\n",
    "imputed_val_X = pd.DataFrame(my_imputer.transform(label_X_val))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_train_X.columns = label_X_train.columns\n",
    "imputed_val_X.columns = label_X_val.columns\n",
    "\n",
    "print(\"MAE from 2nd approach \")\n",
    "score_all(imputed_train_X, imputed_val_X, train_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b23687e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhammed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\muhammed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\muhammed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\muhammed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\muhammed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from 3rd approach \n",
      "31781.240424418604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhammed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#thrid (3rd) approach to hadling missing data\n",
    "\n",
    "# making copy of the data to avoid changing originall data\n",
    "train_X_plus = OH_X_train.copy()\n",
    "val_X_plus  = OH_X_valid.copy()\n",
    "\n",
    "#find columns with missing data\n",
    "col_with_missing = [col for col in OH_X_train.columns\n",
    "                   if OH_X_train[col].isnull().any()]\n",
    "\n",
    "#looping through the missing columns to add extra information\n",
    "for col in col_with_missing:\n",
    "    train_X_plus[col + '__was missing'] = train_X_plus[col].isnull()\n",
    "    val_X_plus[col + '__was missing'] = val_X_plus[col].isnull()\n",
    "    \n",
    "#imputer\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_train_X_plus = pd.DataFrame(my_imputer.fit_transform(train_X_plus))\n",
    "imputed_val_X_plus = pd.DataFrame(my_imputer.fit_transform(val_X_plus))\n",
    "\n",
    "#fix column names\n",
    "imputed_train_X_plus.columns = train_X_plus.columns\n",
    "imputed_val_X_plus.columns = val_X_plus.columns\n",
    "\n",
    "print(\"MAE from 3rd approach \")\n",
    "print(score_all(imputed_train_X_plus, imputed_val_X_plus, train_y, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "862649de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42881.26162790698"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the model with a random state equals 1\n",
    "califonia_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "#fit data and #make predictions\n",
    "califonia_model.fit(imputed_train_X, train_y)\n",
    "preds = califonia_model.predict(imputed_val_X)\n",
    "\n",
    "def scoreall(val_y,preds):\n",
    "    mae = mean_absolute_error(val_y,preds)\n",
    "    return mae\n",
    "\n",
    "scoreall(val_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "74e682ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32406.613267441862"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a better predictions with RandomForestRegressor and make predictions\n",
    "\n",
    "califonia_model_2 = RandomForestRegressor(random_state=1)\n",
    "califonia_model_2.fit(imputed_train_X, train_y)\n",
    "preds_2 = califonia_model_2.predict(imputed_val_X)\n",
    "\n",
    "\n",
    "#measuring the quality of the data\n",
    "\n",
    "def scoreall(val_y,preds_2 ):\n",
    "    mae = mean_absolute_error(val_y,preds_2)\n",
    "    return mae\n",
    "\n",
    "scoreall(val_y, preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00046883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581ccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
